{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Tensors: Vectors & Matrices\n",
    "\n",
    "This notebook covers the fundamentals of PyTorch tensors - the building blocks of neural networks.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Core Mental Model](#core-mental-model)\n",
    "2. [Vector/Matrix Operations](#vectormatrix-operations)\n",
    "3. [One-Hot vs Embedding Vectors](#one-hot-vs-embedding-vectors)\n",
    "4. [Tiny Exercise: Batch Operations](#tiny-exercise-batch-operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Check PyTorch version and device\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'cuda' if torch.cuda.is_available() else 'cpu'}\")\n",
    "device = torch.device('cpu')  # We'll use CPU for reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Mental Model\n",
    "\n",
    "Tensors are n-dimensional arrays that carry data and gradients through neural networks. Think of them as generalized matrices that know how to compute derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic tensor creation\n",
    "x = torch.tensor([1.0, 2.0, 3.0])  # 1D tensor (vector)\n",
    "print(f\"x: {x}, shape: {x.shape}, dtype: {x.dtype}\")\n",
    "\n",
    "# Common creation patterns\n",
    "zeros = torch.zeros(3, 4)  # 3x4 matrix of zeros\n",
    "ones = torch.ones(2, 3, 4)  # 2x3x4 tensor of ones  \n",
    "randn = torch.randn(2, 5)  # Random normal distribution\n",
    "arange = torch.arange(0, 10, 2)  # [0, 2, 4, 6, 8]\n",
    "\n",
    "# Inspect tensor properties\n",
    "print(f\"zeros shape: {zeros.shape}\")\n",
    "print(f\"zeros device: {zeros.device}\")  \n",
    "print(f\"zeros requires_grad: {zeros.requires_grad}\")\n",
    "\n",
    "print(f\"\\nones shape: {ones.shape}\")\n",
    "print(f\"randn shape: {randn.shape}\")\n",
    "print(f\"arange: {arange}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector/Matrix Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication and broadcasting\n",
    "batch_size, d_input, d_hidden = 4, 6, 8\n",
    "X = torch.randn(batch_size, d_input)  # Batch of inputs [B, D_in]\n",
    "W = torch.randn(d_input, d_hidden)    # Weight matrix [D_in, D_out]\n",
    "b = torch.randn(d_hidden)             # Bias vector [D_out]\n",
    "\n",
    "# Linear transformation: y = XW + b\n",
    "y = X @ W + b  # Broadcasting handles bias addition\n",
    "print(f\"X shape: {X.shape}, W shape: {W.shape}, y shape: {y.shape}\")\n",
    "\n",
    "# Indexing and slicing\n",
    "first_sample = X[0]      # First sample: [D_in]\n",
    "first_two = X[:2]        # First two samples: [2, D_in]\n",
    "last_dim = X[..., -1]    # Last feature across all samples: [B]\n",
    "\n",
    "print(f\"\\nFirst sample shape: {first_sample.shape}\")\n",
    "print(f\"First two samples shape: {first_two.shape}\")\n",
    "print(f\"Last dimension across batch shape: {last_dim.shape}\")\n",
    "\n",
    "# Stacking and concatenation\n",
    "X1 = torch.randn(4, 6)\n",
    "X2 = torch.randn(4, 6)\n",
    "stacked = torch.stack([X1, X2], dim=0)  # [2, 4, 6] - adds new dimension\n",
    "concat = torch.cat([X1, X2], dim=0)     # [8, 6] - concatenates along existing dimension\n",
    "\n",
    "print(f\"\\nX1 shape: {X1.shape}, X2 shape: {X2.shape}\")\n",
    "print(f\"Stacked shape: {stacked.shape}\")\n",
    "print(f\"Concatenated shape: {concat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot vs Embedding Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot: sparse, large, inefficient for large vocabularies\n",
    "vocab_size = 1000\n",
    "token_id = 42\n",
    "onehot = torch.zeros(vocab_size)\n",
    "onehot[token_id] = 1.0\n",
    "print(f\"One-hot vector size: {onehot.shape}, mostly zeros: {torch.sum(onehot == 0).item()}\")\n",
    "\n",
    "# Embedding: dense, learnable, efficient\n",
    "embedding_dim = 64\n",
    "embedding_layer = nn.Embedding(vocab_size, embedding_dim)\n",
    "embedded = embedding_layer(torch.tensor([token_id]))\n",
    "print(f\"Embedding vector size: {embedded.shape}, all meaningful values\")\n",
    "\n",
    "# Why embeddings are better:\n",
    "print(\"\\nWhy embeddings are better:\")\n",
    "print(f\"1. Memory: {embedding_dim} floats vs {vocab_size} floats\")\n",
    "print(\"2. Computation: Dense ops vs sparse ops\")\n",
    "print(\"3. Learning: Embeddings learn representations, one-hot is fixed\")\n",
    "\n",
    "# Demonstrate embedding learning\n",
    "batch_tokens = torch.tensor([1, 5, 10, 42, 100])  # Batch of token IDs\n",
    "batch_embedded = embedding_layer(batch_tokens)\n",
    "print(f\"\\nBatch tokens shape: {batch_tokens.shape}\")\n",
    "print(f\"Batch embeddings shape: {batch_embedded.shape}\")\n",
    "\n",
    "# Show that embeddings are learnable parameters\n",
    "print(f\"\\nEmbedding layer has {embedding_layer.weight.numel():,} learnable parameters\")\n",
    "print(f\"Embedding weight shape: {embedding_layer.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tiny Exercise: Batch Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct batch data\n",
    "batch_size, d_model = 3, 4\n",
    "X_batch = torch.randn(batch_size, d_model)  # [B, D]\n",
    "W_linear = torch.randn(d_model, d_model)    # [D, D]\n",
    "b_linear = torch.randn(d_model)             # [D]\n",
    "\n",
    "# Compute linear transformation\n",
    "y_batch = X_batch @ W_linear + b_linear     # [B, D]\n",
    "\n",
    "# Verify shapes\n",
    "assert X_batch.shape == (batch_size, d_model)\n",
    "assert y_batch.shape == (batch_size, d_model)\n",
    "print(\"âœ“ Shape assertions passed\")\n",
    "\n",
    "# Element-wise operations\n",
    "relu_output = torch.relu(y_batch)          # Apply ReLU activation\n",
    "squared = torch.pow(y_batch, 2)            # Element-wise square\n",
    "exp_output = torch.exp(y_batch)           # Element-wise exponential\n",
    "\n",
    "print(f\"\\nOriginal output:\\n{y_batch}\")\n",
    "print(f\"\\nAfter ReLU (negative values -> 0):\\n{relu_output}\")\n",
    "print(f\"\\nSquared:\\n{squared}\")\n",
    "\n",
    "# Reduction operations\n",
    "sum_all = torch.sum(y_batch)                    # Sum all elements\n",
    "sum_dim0 = torch.sum(y_batch, dim=0)            # Sum along batch dimension [D]\n",
    "sum_dim1 = torch.sum(y_batch, dim=1)            # Sum along feature dimension [B]\n",
    "mean_batch = torch.mean(y_batch, dim=0)         # Mean across batch [D]\n",
    "\n",
    "print(f\"\\nReduction operations:\")\n",
    "print(f\"Sum all elements: {sum_all.item():.3f}\")\n",
    "print(f\"Sum along batch dim: {sum_dim0} (shape: {sum_dim0.shape})\")\n",
    "print(f\"Sum along feature dim: {sum_dim1} (shape: {sum_dim1.shape})\")\n",
    "print(f\"Mean across batch: {mean_batch} (shape: {mean_batch.shape})\")\n",
    "\n",
    "# Broadcasting example\n",
    "print(f\"\\n=== Broadcasting Demo ===\")\n",
    "A = torch.randn(3, 1)    # [3, 1]\n",
    "B = torch.randn(1, 4)    # [1, 4]\n",
    "C = A + B                # Broadcasting -> [3, 4]\n",
    "\n",
    "print(f\"A shape: {A.shape}\")\n",
    "print(f\"B shape: {B.shape}\")\n",
    "print(f\"A + B shape: {C.shape} (broadcasted!)\")\n",
    "\n",
    "# This is equivalent to:\n",
    "A_expanded = A.expand(3, 4)  # [3, 1] -> [3, 4]\n",
    "B_expanded = B.expand(3, 4)  # [1, 4] -> [3, 4]\n",
    "C_manual = A_expanded + B_expanded\n",
    "\n",
    "print(f\"Manual expansion result matches: {torch.allclose(C, C_manual)}\")\n",
    "\n",
    "print(\"\\nðŸŽ‰ Tensor basics completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}