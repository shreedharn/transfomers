{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Concepts for Neural Networks\n",
    "\n",
    "This notebook contains PyTorch examples demonstrating advanced concepts.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Temperature Scaling](#temperature-scaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temperature Scaling\n",
    "\n",
    "**Formula:** $\\text{softmax}(z/\\tau)$ where $\\tau$ is temperature\n",
    "\n",
    "Controls confidence/uncertainty in predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature effects on generation\n",
    "logits = torch.tensor([2.0, 1.5, 1.0, 0.5])\n",
    "temperatures = [0.1, 0.5, 1.0, 2.0, 10.0]\n",
    "\n",
    "print(\"Temperature effects on probability distribution:\")\n",
    "for temp in temperatures:\n",
    "    probs = torch.softmax(logits / temp, dim=0)\n",
    "    max_prob = probs.max().item()\n",
    "    entropy = -torch.sum(probs * torch.log(probs + 1e-8)).item()\n",
    "    print(f\"T={temp:4.1f}: max_prob={max_prob:.3f}, entropy={entropy:.3f}, probs={probs.numpy()}\")\n",
    "\n",
    "# Sampling with temperature\n",
    "def sample_with_temperature(logits, temperature=1.0, num_samples=1000):\n",
    "    probs = torch.softmax(logits / temperature, dim=0)\n",
    "    samples = torch.multinomial(probs, num_samples, replacement=True)\n",
    "    return samples\n",
    "\n",
    "# Compare sampling distributions\n",
    "for temp in [0.1, 1.0, 5.0]:\n",
    "    samples = sample_with_temperature(logits, temp)\n",
    "    counts = torch.bincount(samples, minlength=len(logits))\n",
    "    empirical_probs = counts.float() / counts.sum()\n",
    "    print(f\"Temperature {temp}: empirical distribution {empirical_probs.numpy()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}